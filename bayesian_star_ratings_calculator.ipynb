{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background:\n",
    "Have you ever found two similar products on an e-commerce site and tried to use the product ratings to decide which product was better?  Sometimes the average rating is not a great way to determine which product is better. For example, should we really conclude that a product with five 5-star ratings (avg rating 5.0) is better than a product with forty-nine 5-star ratings and one 4-star rating (avg rating 4.98)?  Perhaps not. \n",
    "\n",
    "A better (albeit much harder) way to compare products is to use Bayesian inference. Using Bayesian inference, we can compute a range of plausible average ratings called a posterior distribution based on our initial beliefs about the quality of each product (called the prior) and the likelihood of observing a given collection of ratings. In this framework, we can describe our uncertainty about the true quality of a product by looking at the width of the distribution of plausible average ratings. This uncertainty will be largest when a product has few ratings and will diminish as a product gets more ratings. We can therefore make a more informed decision about which product is likely to be better accounting for this uncertainty.  For example, this can allow us to say things like: there is a 54% chance that the true rating for product 1 is above 4 but there is a 82% chance that the true rating for product 2 is above 4. Therefore, we can be more confident that product 2 is a high quality product. \n",
    "\n",
    "The demo below allows you to experiment with these sorts of calculations for yourself by (a) selecting the number of ratings of each type for two products along with (b) the threshold to use when computing probabilities and (c) the strength of your prior beliefs (which determines the sensitivity of the posterior to the ratings you provide). It then displays the posterior distribution and the probabilities that each product is better than the provided threshold.\n",
    "\n",
    "\n",
    "# Instructions:\n",
    "1. In the kernel menu, select restart and run all.\n",
    "2. Drag the sliders to adjust the parameters and update the plot.\n",
    "\n",
    "### Details:\n",
    "* **threshold** - Determines the threshold $t$ used when computing the probability that the true rating is above $t$. \n",
    "\n",
    "* **Prior strength** - Determines how sensitive the ratings are to new ratings (lower means more sensitive, higher means less sensitive).\n",
    "\n",
    "* **Star ratings** - The number of ratings of each type to use when calculating the posterior density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayesian_star_ratings_calculator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9724bfe4caca47ab8ac036ddadd020cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(GridBox(children=(FloatSlider(value=4.0, description='threshold', max=5.0, min=1.0, stylâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interactive_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
